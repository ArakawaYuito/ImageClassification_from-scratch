{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc7df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14453562481438365281\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7798259712\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12152733939843995739\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Augmentor\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.python.client import device_lib; print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5841ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AugOneImage(img, label, size=10):\n",
    "    rotation_datagen = ImageDataGenerator(rotation_range = 10, \n",
    "                                      shear_range = 10,\n",
    "                                      width_shift_range=0.01,\n",
    "                                     height_shift_range=0.01,\n",
    "                                     zoom_range=0.1)\n",
    "#   imgの形状 =（バッチ数×縦×横×チャンネル数）\n",
    "    img_iter=rotation_datagen.flow(img, batch_size = 1, seed = 0)\n",
    "    aug_imgs=[]\n",
    "    aug_labels=[]\n",
    "    aug_imgs.append(img[0])\n",
    "    aug_labels.append(label)\n",
    "    size-=1\n",
    "    for i, img_gen in enumerate(img_iter):\n",
    "        if i == size:\n",
    "          break\n",
    "        aug_imgs.append(img_gen[0])\n",
    "        aug_labels.append(label)\n",
    "    return np.array(aug_imgs), np.array(aug_labels)\n",
    "\n",
    "def AugAllImage(train_img, label, aug_size):\n",
    "    aug_all_imgs=[]\n",
    "    aug_all_labels=[]\n",
    "    for img_data in zip(train_img, label):\n",
    "        img=img_data[0].transpose(1, 2, 0)[np.newaxis, :, :, :]\n",
    "\n",
    "        aug_imgs, aug_labels=AugOneImage(img, img_data[1], aug_size)\n",
    "        aug_all_imgs.extend(aug_imgs)\n",
    "        aug_all_labels.extend(aug_labels)\n",
    "    return np.array(aug_all_imgs), np.array(aug_all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf84f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbef865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) \n",
    "print(y_train.shape)\n",
    "print(x_test.shape) \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2b772e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 教師ラベルをonehotエンコード\n",
    "enc = OneHotEncoder(categories=\"auto\", sparse_output=False, dtype=np.float32)\n",
    "y_train=enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test=enc.fit_transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0934e149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape= (60000, 1, 28, 28)\n",
      "train_label.shape= (60000, 10)\n",
      "test_data.shape= (10000, 1, 28, 28)\n",
      "test_label.shape= (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train= x_train.reshape(-1, 1, 28, 28)\n",
    "X_test= x_test.reshape(-1, 1, 28, 28)\n",
    "print(\"train_data.shape=\", X_train.shape)\n",
    "print(\"train_label.shape=\", y_train.shape)\n",
    "print(\"test_data.shape=\", X_test.shape)\n",
    "print(\"test_label.shape=\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff068e",
   "metadata": {},
   "source": [
    "## 訓練データ拡張\n",
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d11b9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 1, 28, 28) (600000, 10)\n"
     ]
    }
   ],
   "source": [
    "aug_size=10\n",
    "aug_imgs, aug_labels=AugAllImage(X_train, y_train, aug_size)\n",
    "\n",
    "X_train=aug_imgs.transpose(0, 3, 1, 2)\n",
    "y_train=aug_labels\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b018006",
   "metadata": {},
   "source": [
    "### Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87c44103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 1, 28, 28) (600000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arakawa\\anaconda3\\envs\\jdla\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p = Augmentor.DataPipeline(X_train, y_train.argmax(axis=1).tolist())\n",
    "p.random_distortion(probability=1, grid_width=1, grid_height=1, magnitude=7)\n",
    "x_aug, y_aug=p.sample(X_train.shape[0])\n",
    "x_aug=np.array(x_aug)\n",
    "y_aug=np.array(y_aug).reshape(-1, 1)\n",
    "oh_enc=OneHotEncoder(categories=[np.arange(y_train.shape[1]).tolist()], sparse=False)\n",
    "y_aug=oh_enc.fit_transform(y_aug)\n",
    "print(x_aug.shape, y_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e4ff6",
   "metadata": {},
   "source": [
    "### ImageDataGeneratorとAugmentorを結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3671e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 1, 28, 28) (1200000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.vstack([X_train, x_aug])\n",
    "y_train=np.vstack([y_train, y_aug])\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e427b8",
   "metadata": {},
   "source": [
    "## 前処理\n",
    "### 正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4a381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.min()) / (X_train.max()- X_train.min())\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_test = (X_test - X_test.min()) / (X_test.max()- X_test.min())\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1e9c2",
   "metadata": {},
   "source": [
    "## HDF5出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4ffbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('data/auged_input_data.hdf5', 'w')\n",
    "f.create_dataset('X_train', data=X_train)\n",
    "f.create_dataset('X_test', data=X_test)\n",
    "f.create_dataset('y_train', data=y_train)\n",
    "f.create_dataset('y_test', data=y_test)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4708a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jdla",
   "language": "python",
   "name": "jdla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
